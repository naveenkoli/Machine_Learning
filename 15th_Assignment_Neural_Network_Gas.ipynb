{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9451bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca353fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\hp\\\\Downloads\\\\gas_turbines.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4223966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.439778</td>\n",
       "      <td>-0.826644</td>\n",
       "      <td>1.281436</td>\n",
       "      <td>-0.921232</td>\n",
       "      <td>-1.379101</td>\n",
       "      <td>-1.488376</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.231172</td>\n",
       "      <td>-1.357331</td>\n",
       "      <td>0.532012</td>\n",
       "      <td>1.387845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.449601</td>\n",
       "      <td>-0.748647</td>\n",
       "      <td>1.304564</td>\n",
       "      <td>-0.921495</td>\n",
       "      <td>-1.363528</td>\n",
       "      <td>-1.482325</td>\n",
       "      <td>0.585240</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.363676</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.393002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.434721</td>\n",
       "      <td>-0.686250</td>\n",
       "      <td>1.219086</td>\n",
       "      <td>-0.944385</td>\n",
       "      <td>-1.351309</td>\n",
       "      <td>-1.476275</td>\n",
       "      <td>0.568715</td>\n",
       "      <td>-1.230541</td>\n",
       "      <td>-1.360957</td>\n",
       "      <td>0.552938</td>\n",
       "      <td>1.363586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.413702</td>\n",
       "      <td>-0.623853</td>\n",
       "      <td>1.169060</td>\n",
       "      <td>-0.946884</td>\n",
       "      <td>-1.348194</td>\n",
       "      <td>-1.464173</td>\n",
       "      <td>0.583969</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.356424</td>\n",
       "      <td>0.548933</td>\n",
       "      <td>1.382878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.368693</td>\n",
       "      <td>-0.545857</td>\n",
       "      <td>1.161883</td>\n",
       "      <td>-0.924389</td>\n",
       "      <td>-1.354663</td>\n",
       "      <td>-1.458123</td>\n",
       "      <td>0.582698</td>\n",
       "      <td>-1.229909</td>\n",
       "      <td>-1.350985</td>\n",
       "      <td>0.574179</td>\n",
       "      <td>1.348591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>-1.153182</td>\n",
       "      <td>-1.185428</td>\n",
       "      <td>1.401860</td>\n",
       "      <td>-0.865850</td>\n",
       "      <td>-1.498657</td>\n",
       "      <td>-2.063184</td>\n",
       "      <td>0.103453</td>\n",
       "      <td>-1.426381</td>\n",
       "      <td>-1.543161</td>\n",
       "      <td>1.145792</td>\n",
       "      <td>1.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>-1.303986</td>\n",
       "      <td>-1.138630</td>\n",
       "      <td>1.447753</td>\n",
       "      <td>-0.913470</td>\n",
       "      <td>-1.438759</td>\n",
       "      <td>-2.268905</td>\n",
       "      <td>-0.276638</td>\n",
       "      <td>-1.415642</td>\n",
       "      <td>-1.513247</td>\n",
       "      <td>1.293578</td>\n",
       "      <td>1.119943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>-1.386267</td>\n",
       "      <td>-1.076233</td>\n",
       "      <td>1.476971</td>\n",
       "      <td>-0.951488</td>\n",
       "      <td>-1.410967</td>\n",
       "      <td>-2.789257</td>\n",
       "      <td>-1.026650</td>\n",
       "      <td>-1.516089</td>\n",
       "      <td>-1.467922</td>\n",
       "      <td>2.695925</td>\n",
       "      <td>2.170062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>-1.420423</td>\n",
       "      <td>-0.998236</td>\n",
       "      <td>1.441590</td>\n",
       "      <td>-0.988848</td>\n",
       "      <td>-1.447624</td>\n",
       "      <td>-2.456474</td>\n",
       "      <td>-0.528337</td>\n",
       "      <td>-1.481343</td>\n",
       "      <td>-1.422598</td>\n",
       "      <td>1.924683</td>\n",
       "      <td>2.391165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>-1.430734</td>\n",
       "      <td>-0.935839</td>\n",
       "      <td>1.334652</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-1.464635</td>\n",
       "      <td>-2.051083</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>-1.428277</td>\n",
       "      <td>-1.377273</td>\n",
       "      <td>1.354150</td>\n",
       "      <td>2.321539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -1.439778 -0.826644  1.281436 -0.921232 -1.379101 -1.488376  0.585240   \n",
       "1     -1.449601 -0.748647  1.304564 -0.921495 -1.363528 -1.482325  0.585240   \n",
       "2     -1.434721 -0.686250  1.219086 -0.944385 -1.351309 -1.476275  0.568715   \n",
       "3     -1.413702 -0.623853  1.169060 -0.946884 -1.348194 -1.464173  0.583969   \n",
       "4     -1.368693 -0.545857  1.161883 -0.924389 -1.354663 -1.458123  0.582698   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15034 -1.153182 -1.185428  1.401860 -0.865850 -1.498657 -2.063184  0.103453   \n",
       "15035 -1.303986 -1.138630  1.447753 -0.913470 -1.438759 -2.268905 -0.276638   \n",
       "15036 -1.386267 -1.076233  1.476971 -0.951488 -1.410967 -2.789257 -1.026650   \n",
       "15037 -1.420423 -0.998236  1.441590 -0.988848 -1.447624 -2.456474 -0.528337   \n",
       "15038 -1.430734 -0.935839  1.334652 -1.016605 -1.464635 -2.051083  0.057689   \n",
       "\n",
       "             7         8         9         10  \n",
       "0     -1.231172 -1.357331  0.532012  1.387845  \n",
       "1     -1.229909 -1.363676  0.568733  1.393002  \n",
       "2     -1.230541 -1.360957  0.552938  1.363586  \n",
       "3     -1.229909 -1.356424  0.548933  1.382878  \n",
       "4     -1.229909 -1.350985  0.574179  1.348591  \n",
       "...         ...       ...       ...       ...  \n",
       "15034 -1.426381 -1.543161  1.145792  1.085751  \n",
       "15035 -1.415642 -1.513247  1.293578  1.119943  \n",
       "15036 -1.516089 -1.467922  2.695925  2.170062  \n",
       "15037 -1.481343 -1.422598  1.924683  2.391165  \n",
       "15038 -1.428277 -1.377273  1.354150  2.321539  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "a = StandardScaler()\n",
    "a.fit(data)\n",
    "data_std = a.transform(data)\n",
    "data1 = pd.DataFrame(data_std)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "115fe30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1c7f5b6f3d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f5b6f6a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b847f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b84ac0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b92be0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b92eb0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba0fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bab2e0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb9400>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb96d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bc77f0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bc7ac0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd3be0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd3eb0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be1fd0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bed2e0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfc400>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfc6d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c076d0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c079a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c15ac0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c15d90>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1c7f5b6fa30>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f5b6fc40>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b84d90>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b920a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba01c0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba0490>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bab5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bab880>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb99a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb9c70>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bc7d90>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd30a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be11c0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be1490>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bed5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bed880>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfc9a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfcc70>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c07c70>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c07f40>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c220a0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c22370>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1c7f5b6f100>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b84520>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b92910>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba0d00>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb9130>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bc7520>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd3910>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be1d00>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfc130>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c07400>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c157f0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1c7f5b6ff10>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b92370>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba0760>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7babb50>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bb9f40>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd3370>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be1760>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bedb50>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bfcdf0>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c15250>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c22640>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1c7f7b84220>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7b92640>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7ba0a30>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7babe20>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bc7250>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bd3640>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7be1a30>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7bede20>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c07130>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c15520>,\n",
       "  <matplotlib.lines.Line2D at 0x1c7f7c22910>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80882cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1.plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1243edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting our data :- \n",
    "\n",
    "X = data1.iloc[:,[0,1,2,3,4,5,6,8,9,10]]\n",
    "Y = data1.iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd664a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our model :-\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# as this is linear regression problem we have to choose activation function as linear\n",
    "model.add(layers.Dense(10, input_dim=10, activation='linear'))\n",
    "model.add(layers.Dense(8, activation='linear'))  # hidder layer\n",
    "model.add(layers.Dense(1, activation='linear')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76303b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will compile our model :-\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['MSE'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43590e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1c7f8c77730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e1bef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "211/211 [==============================] - 3s 8ms/step - loss: 0.0711 - MSE: 0.0711 - val_loss: 0.0031 - val_MSE: 0.0031\n",
      "Epoch 2/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0024 - MSE: 0.0024 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 3/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 4/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 5/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 6/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 7/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 8/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 9/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 10/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 11/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 12/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 13/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 14/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 15/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 16/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 17/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0029 - val_MSE: 0.0029\n",
      "Epoch 18/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 19/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 20/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 21/300\n",
      "211/211 [==============================] - 2s 9ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 22/300\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 23/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 24/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 25/300\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 26/300\n",
      "211/211 [==============================] - 2s 8ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 27/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 28/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 29/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 30/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 31/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 32/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 33/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 34/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 35/300\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 36/300\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 37/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 38/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 39/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 40/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 41/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 42/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 43/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 44/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 45/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 46/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 47/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0034 - val_MSE: 0.0034\n",
      "Epoch 48/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 49/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 50/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 51/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0030 - val_MSE: 0.0030\n",
      "Epoch 52/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 53/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 54/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 55/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 56/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 57/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 58/300\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 59/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0027 - val_MSE: 0.0027\n",
      "Epoch 60/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 61/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 63/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 64/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 65/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 66/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 67/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 68/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 69/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 70/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 71/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 72/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 73/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 74/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 75/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 76/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 77/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 78/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 79/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 80/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 81/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 82/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 83/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 84/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 85/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 86/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 87/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 88/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 89/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 90/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 91/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 92/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0027 - val_MSE: 0.0027\n",
      "Epoch 93/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 94/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 95/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 96/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 97/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 98/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 99/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 100/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 101/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 102/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 103/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 104/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 105/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 106/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 107/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 108/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 109/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 110/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 111/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 112/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 113/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 114/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 115/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 116/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 117/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 118/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0028 - val_MSE: 0.0028\n",
      "Epoch 119/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 120/300\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 121/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 122/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 124/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 125/300\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 126/300\n",
      "211/211 [==============================] - 2s 10ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 127/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 128/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0027 - val_MSE: 0.0027\n",
      "Epoch 129/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0023 - MSE: 0.0023 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 130/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 131/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 132/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 133/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 134/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 135/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 136/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 137/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 138/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 139/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 140/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 141/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 142/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 143/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 144/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 145/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 146/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 147/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 148/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 149/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 150/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 151/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 152/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 153/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 154/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 155/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 156/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 157/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 158/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 159/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 160/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 161/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 162/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 163/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 164/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 165/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 166/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 167/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 168/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 169/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 170/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 171/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 172/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 173/300\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 174/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 175/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 176/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 177/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 178/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 179/300\n",
      "211/211 [==============================] - 2s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 180/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 181/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 182/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 183/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 185/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 186/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 187/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 188/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 189/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 190/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 191/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 192/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 193/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 194/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 195/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 196/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 197/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 198/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 199/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 200/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 201/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 202/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 203/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 204/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 205/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 206/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 207/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 208/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 209/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 210/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 211/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 212/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 213/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 214/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0030 - val_MSE: 0.0030\n",
      "Epoch 215/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 216/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 217/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 218/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0025 - val_MSE: 0.0025\n",
      "Epoch 219/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 220/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 221/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 222/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 223/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 224/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 225/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 226/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 227/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 228/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 229/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 230/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 231/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 232/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 233/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 234/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 235/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 236/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 237/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 238/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0027 - val_MSE: 0.0027\n",
      "Epoch 239/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 240/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 241/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 242/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 243/300\n",
      "211/211 [==============================] - 1s 7ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 244/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 245/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 246/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 247/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 248/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 249/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 250/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 251/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 252/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 253/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 254/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 255/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 256/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 257/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 258/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 259/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 260/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 261/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 262/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 263/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0024 - val_MSE: 0.0024\n",
      "Epoch 264/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 265/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 266/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 267/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 268/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 269/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 270/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 271/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 272/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 273/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 274/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 275/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 276/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0020 - val_MSE: 0.0020\n",
      "Epoch 277/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 278/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 279/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 280/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 281/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 282/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 283/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0026 - val_MSE: 0.0026\n",
      "Epoch 284/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 285/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 286/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 287/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 288/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 289/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 290/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 291/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 292/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0021 - val_MSE: 0.0021\n",
      "Epoch 293/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 294/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 295/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 296/300\n",
      "211/211 [==============================] - 1s 5ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 297/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 298/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0022 - MSE: 0.0022 - val_loss: 0.0023 - val_MSE: 0.0023\n",
      "Epoch 299/300\n",
      "211/211 [==============================] - 1s 6ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0022 - val_MSE: 0.0022\n",
      "Epoch 300/300\n",
      "211/211 [==============================] - 1s 4ms/step - loss: 0.0021 - MSE: 0.0021 - val_loss: 0.0024 - val_MSE: 0.0024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c7f90fddc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will fit our data into model and give them parameter :-\n",
    "\n",
    "model.fit(X,Y,  validation_split=0.3, epochs=300, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d61e8758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 3ms/step - loss: 0.0022 - MSE: 0.0022\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c5fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "0.2207649638876319\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names[1])\n",
    "print(score[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e59e6a",
   "metadata": {},
   "source": [
    "# Tuning Hyerparameter :- Batch size and Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4007888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(layers.Dense(10, input_dim=10, activation='linear'))\n",
    "    model1.add(layers.Dense(8, activation='linear'))  # hidder layer\n",
    "    model1.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    #adam = Adam(lr=0.01)\n",
    "    model1.compile(loss='mean_squared_error', optimizer='adam', metrics=['MSE'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result.best_params_)\n",
    "print(grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff84a4d7",
   "metadata": {},
   "source": [
    "##  Total MSE 0.2207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569c2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
